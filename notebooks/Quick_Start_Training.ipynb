{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed5568b",
   "metadata": {},
   "source": [
    "# 🎯 Quick Start: Training BEATs Models\n",
    "\n",
    "Learn how to fine-tune BEATs on your own audio data in just a few steps!\n",
    "\n",
    "## What You'll Learn\n",
    "- Organize your audio data\n",
    "- Train a custom BEATs model\n",
    "- Evaluate model performance\n",
    "\n",
    "**Estimated time**: 15-20 minutes (+ training time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79546eb8",
   "metadata": {},
   "source": [
    "## 1. Install and Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install beats-trainer (uncomment if needed)\n",
    "# !pip install git+https://github.com/ninanor/beats-trainer.git\n",
    "\n",
    "from beats_trainer import BEATsTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"✅ Ready to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a84ce1",
   "metadata": {},
   "source": [
    "## 2. Prepare Your Data\n",
    "\n",
    "### Option A: Directory Structure (Easiest)\n",
    "Organize your audio files like this:\n",
    "```\n",
    "your_dataset/\n",
    "├── class1/\n",
    "│   ├── audio1.wav\n",
    "│   ├── audio2.wav\n",
    "│   └── audio3.wav\n",
    "├── class2/\n",
    "│   ├── audio4.wav\n",
    "│   └── audio5.wav\n",
    "└── class3/\n",
    "    └── audio6.wav\n",
    "```\n",
    "\n",
    "### Option B: CSV File\n",
    "Create a CSV with audio paths and labels:\n",
    "```csv\n",
    "filename,category\n",
    "audio/sample1.wav,bird\n",
    "audio/sample2.wav,dog\n",
    "audio/sample3.wav,cat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual dataset path\n",
    "dataset_path = \"path/to/your/audio/dataset\"\n",
    "\n",
    "# Check if dataset exists\n",
    "if Path(dataset_path).exists():\n",
    "    print(f\"✅ Found dataset at: {dataset_path}\")\n",
    "\n",
    "    # Create trainer from directory structure\n",
    "    trainer = BEATsTrainer.from_directory(dataset_path)\n",
    "    print(f\"🎯 Dataset loaded: {len(trainer.dataset)} samples\")\n",
    "    print(f\"📊 Classes: {trainer.dataset_stats['num_classes']}\")\n",
    "\n",
    "else:\n",
    "    print(\"📝 Please update 'dataset_path' with your actual dataset path\")\n",
    "    print(\"\\n💡 For demo purposes, here's how you'd load different data types:\")\n",
    "\n",
    "    print(\"\\n# Method 1: From directory\")\n",
    "    print('trainer = BEATsTrainer.from_directory(\"/path/to/audio/classes\")')\n",
    "\n",
    "    print(\"\\n# Method 2: From CSV\")\n",
    "    print('trainer = BEATsTrainer.from_csv(\"labels.csv\", data_dir=\"/path/to/audio\")')\n",
    "\n",
    "    print(\"\\n# Method 3: From preset dataset (ESC-50, UrbanSound8K)\")\n",
    "    print('trainer = BEATsTrainer.from_preset(\"esc50\", \"/path/to/ESC-50-master\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4185e1",
   "metadata": {},
   "source": [
    "## 3. Configure Training (Optional)\n",
    "\n",
    "The default settings work well for most cases, but you can customize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ab1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beats_trainer.config import Config, TrainingConfig\n",
    "\n",
    "# Optional: Custom training configuration\n",
    "config = Config()\n",
    "config.training = TrainingConfig(\n",
    "    learning_rate=5e-5,  # Lower learning rate for fine-tuning\n",
    "    max_epochs=20,  # Number of training epochs\n",
    "    batch_size=16,  # Adjust based on your GPU memory\n",
    "    patience=5,  # Early stopping patience\n",
    ")\n",
    "\n",
    "print(\"⚙️  Training configuration:\")\n",
    "print(f\"   Learning rate: {config.training.learning_rate}\")\n",
    "print(f\"   Max epochs: {config.training.max_epochs}\")\n",
    "print(f\"   Batch size: {config.training.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2094a97",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "This will fine-tune BEATs on your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training (this will take some time!)\n",
    "if \"trainer\" in locals():\n",
    "    print(\"🚀 Starting training...\")\n",
    "    print(\"⏰ This will take several minutes depending on your dataset size and GPU\")\n",
    "\n",
    "    # Train the model\n",
    "    results = trainer.train()\n",
    "\n",
    "    print(\"🎉 Training completed!\")\n",
    "    print(f\"📈 Best validation accuracy: {results['best_score']:.3f}\")\n",
    "    print(f\"💾 Model saved to: {results['best_checkpoint']}\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  Skipping training - no dataset loaded\")\n",
    "    print(\"   Update the dataset path in step 2 to run training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e3a67",
   "metadata": {},
   "source": [
    "## 5. Use Your Trained Model\n",
    "\n",
    "Extract features with your custom-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5286ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"trainer\" in locals() and \"results\" in locals():\n",
    "    # Get feature extractor with trained model\n",
    "    custom_extractor = trainer.get_feature_extractor()\n",
    "\n",
    "    print(\"✅ Custom model feature extractor ready!\")\n",
    "    print(\"🎯 You can now use this for feature extraction:\")\n",
    "    print(\"   features = custom_extractor.extract_from_file('new_audio.wav')\")\n",
    "\n",
    "    # Example prediction (if predict method is implemented)\n",
    "    try:\n",
    "        # This would predict on new audio files\n",
    "        # predictions = trainer.predict(['new_audio1.wav', 'new_audio2.wav'])\n",
    "        print(\"🔮 Model ready for predictions on new audio!\")\n",
    "    except NotImplementedError:\n",
    "        print(\"🔮 Prediction feature coming soon!\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  No trained model available\")\n",
    "    print(\"   Complete the training step to get a custom model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d897d97",
   "metadata": {},
   "source": [
    "## 6. Compare Models\n",
    "\n",
    "Let's compare your trained model with the pretrained one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd345c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beats_trainer import BEATsFeatureExtractor\n",
    "\n",
    "# Create both extractors for comparison\n",
    "pretrained_extractor = BEATsFeatureExtractor()  # Pretrained model\n",
    "\n",
    "if \"custom_extractor\" in locals():\n",
    "    print(\"🔍 Comparing pretrained vs custom-trained models:\")\n",
    "    print(\"   Pretrained model: General audio understanding\")\n",
    "    print(\n",
    "        f\"   Custom model: Specialized for your {trainer.dataset_stats['num_classes']} classes\"\n",
    "    )\n",
    "\n",
    "    # You could extract features from the same audio with both models\n",
    "    # and compare their similarity/clustering performance\n",
    "\n",
    "else:\n",
    "    print(\"📊 Only pretrained model available for now\")\n",
    "    print(\"   Complete training to get both models for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7dae0",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "🎉 **Great job!** You've learned how to train custom BEATs models.\n",
    "\n",
    "### What's Next?\n",
    "- **Evaluate**: Test your model on held-out data\n",
    "- **Deploy**: Use your model in production applications  \n",
    "- **Iterate**: Experiment with different hyperparameters\n",
    "- **Scale**: Try larger datasets for better performance\n",
    "\n",
    "### Tips for Better Results\n",
    "- **More data**: 50+ samples per class minimum\n",
    "- **Balanced classes**: Similar number of samples per class\n",
    "- **Clean audio**: Remove background noise when possible\n",
    "- **Augmentation**: Built-in data augmentation helps with small datasets\n",
    "\n",
    "### Need Help?\n",
    "- 📖 [Documentation](https://github.com/ninanor/beats-trainer)\n",
    "- 🐛 [Report Issues](https://github.com/ninanor/beats-trainer/issues)\n",
    "- 💬 Ask questions in the repository discussions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
